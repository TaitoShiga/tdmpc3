# 追加の考察用分析案

## 🎯 基本分析（必須）

### 1. **学習曲線・最終性能の比較**
✅ 実装済み (`analyze_eval_results.py`)
- DR < C < O の関係を検証
- 評価曲線のプロット
- 最終性能の統計的比較

---

## 🔬 追加分析案

### 2. **物理パラメータ推定精度の分析（Model C）**
**目的:** GRUがどれだけ正確に質量を推定できているかを定量評価

**分析内容:**
- エピソード全体での推定質量 vs 真の質量のプロット
- 推定誤差の時系列変化（エピソード序盤 vs 終盤）
- 異なる質量範囲での推定精度の比較
- コンテキスト長（過去の履歴長）と推定精度の関係

**実装:**
```python
# 推定精度の可視化
- 散布図: 真の質量 vs 推定質量（対角線=完璧な推定）
- ヒートマップ: 質量範囲 × 推定誤差
- 時系列: エピソード内での推定値の収束
```

**期待される結果:**
- 推定誤差が学習とともに減少
- エピソード序盤で推定が不安定、終盤で安定
- 訓練範囲内の質量は高精度、範囲外は誤差増加

---

### 3. **Zero-Shot 汎化性能の評価**
**目的:** 訓練時に見ていない質量に対する汎化能力を測定

**分析内容:**
- **In-Distribution（訓練範囲内）:** 質量 = 0.5～2.0
- **Out-of-Distribution（訓練範囲外）:** 質量 = 0.2, 3.0, 5.0
- 各モデル（DR, C, O）のOOD性能を比較

**実装:**
```python
# 様々な質量でテスト
masses_in_dist = [0.5, 1.0, 1.5, 2.0]
masses_ood = [0.2, 0.3, 2.5, 3.0, 5.0]

# 各質量での平均報酬をプロット
# 訓練範囲を縦線で表示
```

**期待される結果:**
- Model O: 常に最高性能（真の質量を知っているため）
- Model C: In-Distで高性能、OODで劣化（ただしDRより良い）
- Model B (DR): In-Dist/OODともに安定だが性能は低い

---

### 4. **学習効率の分析（Sample Efficiency）**
**目的:** 同じ性能に到達するまでに必要なサンプル数を比較

**分析内容:**
- 各モデルが報酬 X に到達するまでのステップ数
- 学習速度の比較（初期 vs 中盤 vs 後半）
- プラトー（停滞）の有無

**実装:**
```python
# 報酬閾値（例: 500, 700）に到達するステップ数
threshold_rewards = [200, 400, 600, 700]
for model in [DR, C, O]:
    steps_to_reach = find_first_crossing(model, threshold_rewards)
    # 棒グラフで比較
```

**期待される結果:**
- Model O: 最も早く収束（完璧な情報を持つため）
- Model C: 中程度（GRUの推定が安定してから加速）
- Model B (DR): 最も遅い（曖昧な情報で学習）

---

### 5. **Planning の質の分析**
**目的:** MPPI プランニングの質を評価

**分析内容:**
- **Q値の分散:** Q値が高いほど良い計画
- **予測報酬 vs 実際の報酬:** World Modelの予測精度
- **計画のホライゾン:** 短期 vs 長期計画の比較

**実装:**
```python
# プランニング中の Q値の記録
# 各モデルでの Q値の時系列変化
# 予測報酬と実際の報酬の相関
```

**期待される結果:**
- Model O: 最も正確な予測、高い Q値
- Model C: 推定が正確なら O に近い
- Model B (DR): 予測が不安定、Q値が低い

---

### 6. **Ablation Study（アブレーション）**
**目的:** Model C の各コンポーネントの寄与を分析

**実験設定:**
| モデル | 説明 |
|--------|------|
| Model C (Full) | GRU推定器 + 勾配分離 + 2フェーズ学習 |
| Model C w/o Gradient Sep | 勾配分離なし（GRUとプランナーが干渉） |
| Model C w/ MLP | GRU → MLP に置き換え |
| Model C w/o Pretraining | GRU事前学習なし |
| Model C (Context=10) | コンテキスト長を10に短縮 |
| Model C (Context=100) | コンテキスト長を100に延長 |

**期待される結果:**
- 勾配分離なし → 学習が不安定
- MLP → 時系列情報を活用できず性能低下
- 事前学習なし → 収束が遅い
- コンテキスト長 → 短すぎると推定不安定、長すぎても効果薄い

---

### 7. **物理パラメータの感度分析**
**目的:** 質量の変化に対する各モデルのロバスト性を測定

**分析内容:**
- 質量を徐々に変化させながら報酬を測定
- 質量 vs 報酬のヒートマップ
- 報酬の標準偏差（ばらつき）の比較

**実装:**
```python
masses = np.linspace(0.2, 3.0, 20)
rewards_dr = []
rewards_c = []
rewards_o = []

for mass in masses:
    # 各モデルで評価（5エピソード平均）
    rewards_dr.append(evaluate(model_dr, mass))
    rewards_c.append(evaluate(model_c, mass))
    rewards_o.append(evaluate(model_o, mass))

# プロット: 質量 vs 報酬（3本の曲線）
```

**期待される結果:**
- Model O: 全質量範囲で最高かつ安定
- Model C: 訓練範囲で高性能、範囲外で劣化
- Model B (DR): 全体的に低いが安定

---

### 8. **エピソード内での推定値の収束分析（Model C）**
**目的:** GRUがエピソード内でどう推定を改善するか可視化

**分析内容:**
- 1エピソード内での推定質量の時系列変化
- 各タイムステップでの推定誤差
- 収束速度の可視化

**実装:**
```python
# エピソード開始時、中盤、終盤での推定値
timesteps = range(0, 500, 10)
estimated_mass = []

for t in timesteps:
    c_phys_pred = gru.estimate(history[:t])
    estimated_mass.append(c_phys_pred)

# プロット: タイムステップ vs 推定質量（真の質量を横線で表示）
```

**期待される結果:**
- 序盤: 推定が大きくブレる
- 中盤: 真の値に近づく
- 終盤: 安定した推定

---

### 9. **注意機構の可視化（もしTransformerを使う場合）**
**目的:** どの過去の時刻が推定に重要か可視化

**分析内容:**
- Attention weight のヒートマップ
- 重要なタイムステップの特定

---

### 10. **失敗ケースの分析**
**目的:** 各モデルが失敗する条件を特定

**分析内容:**
- 報酬が低いエピソードの物理パラメータ
- 失敗時の推定誤差（Model C）
- 失敗時の行動パターン

**実装:**
```python
# 報酬が閾値以下のエピソードを抽出
failed_episodes = episodes[rewards < 200]

# 失敗時の質量分布をヒストグラムで可視化
# 失敗時の推定誤差の分布
```

**期待される結果:**
- Model C: 極端な質量で失敗
- Model B (DR): ランダムに失敗
- Model O: ほとんど失敗しない

---

### 11. **ドメインランダマイゼーションの分布分析**
**目的:** 訓練時の質量分布が性能に与える影響

**分析内容:**
- 訓練時の質量サンプリング分布
- 頻繁に見た質量 vs 稀な質量での性能
- サンプリング戦略の最適化

---

### 12. **計算コストの比較**
**目的:** 各モデルの計算効率を比較

**分析内容:**
- 推論時間（1ステップあたり）
- メモリ使用量
- GFLOPs の比較

**実装:**
```python
import time

# 推論時間の測定
for model in [DR, C, O]:
    start = time.time()
    for _ in range(100):
        action = model.act(obs)
    inference_time = (time.time() - start) / 100
    print(f"{model}: {inference_time*1000:.2f} ms/step")
```

**期待される結果:**
- Model B (DR): 最速（追加の推定なし）
- Model C: 中程度（GRU推定のオーバーヘッド）
- Model O: 最速（推定不要、真の値を直接使用）

---

## 📊 優先度付き実装順序

### 🔥 高優先度（論文に必須）
1. ✅ 学習曲線・最終性能の比較
2. **物理パラメータ推定精度の分析（Model C）**
3. **Zero-Shot 汎化性能の評価**
4. **学習効率の分析**

### 🌟 中優先度（考察を深める）
5. **Planning の質の分析**
6. **物理パラメータの感度分析**
7. **エピソード内での推定値の収束分析**
8. **失敗ケースの分析**

### 💡 低優先度（追加の洞察）
9. **Ablation Study**
10. **ドメインランダマイゼーションの分布分析**
11. **計算コストの比較**
12. **注意機構の可視化**

---

## 🚀 次のステップ

1. **まず `analyze_eval_results.py` を実行して基本結果を確認**
2. **高優先度の分析（2, 3, 4）を実装**
3. **結果に基づいて追加の分析を選択**

実装が必要な分析があれば指示してください！

